{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdpipe as pdp\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load time data\n",
    "df_for_prediction = pd.read_csv(\"../data/transformed/pipeline_data.csv\")\n",
    "\n",
    "# due to time aspect\n",
    "df_for_prediction = df_for_prediction.sort_values(by = ['createdYear', 'createdMonth', 'createdDay'],\n",
    "                                                  ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to drop\n",
    "columns_to_drop = ['Unnamed: 0', 'project', 'status', 'updated', 'key', 'assignee', 'resolution',\n",
    "                   'days_in_current_status', 'reporter', 'steps_taken','time_needed','created_date',\n",
    "                   'Non-existent_Open', '0','1','2','3','4','5','6','7','8','9','10', 'days_needed',\n",
    "                   'Predicted_actions', 'status_event', 'Open_Patch Available','Patch Available_In Progress',\n",
    "                   'Open_Resolved','Patch Available_Resolved', 'Resolved_Reopened', 'Reopened_Resolved',\n",
    "                   'In Progress_Patch Available', 'Patch Available_Open','Reopened_Patch Available',\n",
    "                   'Open_In Progress', 'In Progress_Resolved', 'index.1', 'createdElapsed', 'step0']\n",
    "\n",
    "\n",
    "# columns that will be scaled with robust scaler\n",
    "columns_scaling = ['comment_count', 'description_length', 'summary_length', 'watch_count']\n",
    "# steps taken\n",
    "columns_to_change = ['step1', 'step2', 'step3', 'step4', 'step5', 'step6']\n",
    "# one hot encoding columns\n",
    "columns_onehotencoding = ['steps_taken_combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pdp.ColDrop(columns_to_drop) # drop columns\n",
    "pipeline += pdp.Scale('RobustScaler', columns_scaling) # scale data -> robust scaler, handles outliers\n",
    "#pipeline += pdp.Encode(['assignee', 'steps_taken'])\n",
    "pipeline += pdp.MapColVals('priority', {'Minor': 0, \n",
    "                                       'Trival': 1, \n",
    "                                       'Blocker': 2,\n",
    "                                       'Major': 3,\n",
    "                                       'Critical': 4})\n",
    "pipeline += pdp.MapColVals('issue_type',{'Test': 0,\n",
    "                                        'Bug': 1,\n",
    "                                        'Improvement':2,\n",
    "                                        'Task':3,\n",
    "                                        'Wish':4,\n",
    "                                        'New Feature':5,\n",
    "                                        'Sub-task':6})\n",
    "\n",
    "\n",
    "pipeline += pdp.MapColVals(columns_to_change, {'Non-existent': 0,\n",
    "                                               'Open': 1,\n",
    "                                               'Resolved': 2,\n",
    "                                               'Patch Available': 3,\n",
    "                                               'Reopened': 4,\n",
    "                                               'In Progress': 5,\n",
    "                                               'Reopened': 6,\n",
    "                                                '0': 0,\n",
    "                                              })\n",
    "\n",
    "\n",
    "pipeline += pdp.OneHotEncode(columns_onehotencoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Pipeline\n",
    "Pass training and test data seperately through pipeline, so no data leakage happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_to_train = df_to_train.fillna(0) \n",
    "df_for_prediction = df_for_prediction.fillna(0) # test data\n",
    "df_for_train = df_for_prediction[df_for_prediction['resolutiondate'] != 0] # training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_to_train = pipeline(df_to_train) # pass data through pipeline\n",
    "df_for_prediction = pipeline(df_for_prediction) # pass data through pipeline\n",
    "df_for_train = pipeline(df_for_train) # pass data through pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data that went through pipeline\n",
    "#df_to_train.to_csv('data_for_train.csv')\n",
    "df_for_prediction.to_csv('../data/transformed/prediction_pipelined_data.csv')\n",
    "df_for_train.to_csv('../data/transformed/train_pipeline_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
